{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2024 Semester 1\n",
    "\n",
    "## Assignment 1: Wine quality classification with K-NN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student ID(s):**     1297447\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you will use for your Assignment 1 submission.\n",
    "\n",
    "**NOTE: YOU SHOULD ADD YOUR RESULTS, DIAGRAMS AND IMAGES FROM YOUR OBSERVATIONS IN THIS FILE TO YOUR REPORT (the PDF file).**\n",
    "\n",
    "**Adding proper comments to your code is MANDATORY. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1350 entries, 0 to 1349\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   fixedAcidity        1350 non-null   float64\n",
      " 1   volatileAcidity     1350 non-null   float64\n",
      " 2   citricAcid          1350 non-null   float64\n",
      " 3   residualSugar       1350 non-null   float64\n",
      " 4   chlorides           1350 non-null   float64\n",
      " 5   freeSulfurDioxide   1350 non-null   float64\n",
      " 6   totalSulfurDioxide  1350 non-null   float64\n",
      " 7   density             1350 non-null   float64\n",
      " 8   pH                  1350 non-null   float64\n",
      " 9   sulphates           1350 non-null   float64\n",
      " 10  alcohol             1350 non-null   float64\n",
      " 11  quality             1350 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 126.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Read training dataset from csv file\n",
    "train_dataset = pd.read_csv('winequality-train.csv')\n",
    "train_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1350 entries, 0 to 1349\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   fixedAcidity        1350 non-null   float64\n",
      " 1   volatileAcidity     1350 non-null   float64\n",
      " 2   citricAcid          1350 non-null   float64\n",
      " 3   residualSugar       1350 non-null   float64\n",
      " 4   chlorides           1350 non-null   float64\n",
      " 5   freeSulfurDioxide   1350 non-null   float64\n",
      " 6   totalSulfurDioxide  1350 non-null   float64\n",
      " 7   density             1350 non-null   float64\n",
      " 8   pH                  1350 non-null   float64\n",
      " 9   sulphates           1350 non-null   float64\n",
      " 10  alcohol             1350 non-null   float64\n",
      " 11  quality             1350 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 126.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Read testing dataset from csv file\n",
    "test_dataset = pd.read_csv('winequality-test.csv')\n",
    "test_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-NN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate features and labels in training and testing dataset\n",
    "train_features = train_dataset.drop('quality', axis = 1)\n",
    "train_labels = train_dataset['quality']\n",
    "\n",
    "test_features = test_dataset.drop('quality', axis = 1)\n",
    "test_labels = test_dataset['quality']\n",
    "\n",
    "\n",
    "# Calculate euclidean distance with other features\n",
    "def calc_euclidean_distance(instance, train_features):\n",
    "    return np.sqrt(((instance - train_features) ** 2).sum(axis = 1))\n",
    "\n",
    "\n",
    "# Get neighbors labels from given instance\n",
    "def get_neighbors_labels(distance, train_labels, k):\n",
    "    \n",
    "    # Get k nearest neighbors\n",
    "    neighbors = distance.sort_values()[:k]\n",
    "    neighbors_labels = train_labels.loc[neighbors.index].value_counts()\n",
    "\n",
    "    return neighbors_labels\n",
    "\n",
    "\n",
    "# Predict one instance's label given k and features\n",
    "def predict_instance(instance, train_features, train_labels, k):\n",
    "    \n",
    "    # Calculate euclidean distance\n",
    "    distance = calc_euclidean_distance(instance, train_features)\n",
    "    \n",
    "    # Get neighbors labels\n",
    "    neighbors_labels = get_neighbors_labels(distance, train_labels, k)\n",
    "    \n",
    "    # Use majority vote to pick the label with most votes\n",
    "    # If tie, use 1-NN\n",
    "    if neighbors_labels.get(0) == neighbors_labels.get(1):\n",
    "        neighbors_labels = get_neighbors_labels(distance, train_labels, k = 1)\n",
    "        label = neighbors_labels.index[0]\n",
    "    else:\n",
    "        label = neighbors_labels.sort_values(ascending = False).index[0]\n",
    "    \n",
    "    return label\n",
    "\n",
    "\n",
    "# Predict the quality of wine using K-NN\n",
    "def predict(test_features, train_features, train_labels, k):\n",
    "\n",
    "    predictions = {}\n",
    "\n",
    "    # Predict each instance in test dataset\n",
    "    for i, data in test_features.iterrows():\n",
    "        label = predict_instance(data, train_features, train_labels, k)\n",
    "        predictions[i] = label\n",
    "\n",
    "    return pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 1-NN classification\n",
    "\n",
    "#### NOTE: you may develope codes or functions to help respond to the question here, but your formal answer must be submitted separately as a PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7644444444444445"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = predict(test_features, train_features, train_labels, k = 1)\n",
    "(prediction == test_labels).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normalization\n",
    "\n",
    "#### NOTE: you may develope codes or functions to help respond to the question here, but your formal answer must be submitted separately as a PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model extensions\n",
    "\n",
    "#### NOTE: you may develope codes or functions to help respond to the question here, but your formal answer must be submitted separately as a PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1\n",
    "Compare the performance of your best 1-NN model from Question 3 to a Gaussian naive Bayes model on this dataset (you may use library functions to implement the Gaussian naive Bayes model). In your write-up, state the accuracy of the naive Bayes model and identify instances where the two models disagree. Why do the two models classify these instances differently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2\n",
    "Implement two additional distance measures for your K-NN model: cosine similarity and Mahalanobis distance (you may use library functions for these distance measures). Do 1-NN classification using each of these new distance measures and the three normalization options from Question 3. Discuss how the new distance metrics compare to Euclidean distance and how each metric is affected by normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3\n",
    "Implement either of the two K-NN weighting strategies discussed in lecture (inverse linear distance or inverse distance). Compare the performance of the weighted and majority vote models for a few different values of K. In your write-up, discuss how weighting strategy and the value of K affect the model's decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4\n",
    "Measure the empirical distribution of class labels in the training dataset (what percentage of the training data comes from each class). Then evaluate the distribution of labels predicted by your K-NN model for the test data, for a range of values for K. Does the class distribution of the predicted labels match the class distribution of the training data? Explain why or why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
